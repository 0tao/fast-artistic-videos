<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-dark.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <title>FastArtisticVideos by zeruniverse</title>
  </head>

  <body>

    <header>
      <div class="container">
        <h1>Fast_Artistic_Videos</h1>
        <h2>Fast artistic style transfer for videos</h2>
        <!--IT'S PRIVATE REPO NOW!!!
        <section id="downloads">
          <a href="https://github.com/zeruniverse/fast-artistic-videos/zipball/master" class="btn">Download as .zip</a>
          <a href="https://github.com/zeruniverse/fast-artistic-videos/tarball/master" class="btn">Download as .tar.gz</a>
          <a href="https://github.com/zeruniverse/fast-artistic-videos" class="btn btn-github"><span class="icon"></span>View on GitHub</a>
        </section>-->
      </div>
    </header>

    <div class="container">
      <section id="main_content">
        <h3>
<a id="welcome-to-github-pages" class="anchor" href="#abstract" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h3>

<p>
Recently, research about artistic style transfer, which trains computers to be artists, become popular. 
<a href="https://arxiv.org/abs/1508.06576">Gatys et al.</a> turned this task into an optimization problem and utilized 
convolution neural network to solve this problem. 
However, this method for image stylization doesn't work well for videos due to its failure to consider temporal consistency. 
To solve this problem, <a href="https://arxiv.org/abs/1604.08610">Ruder et al.</a> proposed a method which integrated temporal loss into the loss 
function. But this method is pretty slow. Stylizing a 15-second-video takes more than 7.5 hours.
Earlier this year, 
<a href="http://cs.stanford.edu/people/jcjohns/eccv16/">Johnson et al.</a> made the image stylization procedure real-time by training a neural network 
for this optimization problem instead of optimizing each image separately. By combining the ideas of 
Ruder et al. and Johnson et al., we came up with a new method for video stylization, which <span  style="color:#66ccff">keeps the temporal consistency</span> 
but works <span  style="color:#66ccff">about 10 times</span> as fast as  
the method proposed by Ruder et al. Our method makes it possible to stylize movies and animations with reasonable time costs.

</p>

<h3>
<a id="designer-templates" class="anchor" href="#samples" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Samples</h3>

<p>Weâ€™ve uploaded some sample videos to YouTube.</p>
<h5>
<a id="designer-templates" class="anchor" href="#sample_story" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sample Story (15s)</h5>
<iframe width="560" height="315" src="https://www.youtube.com/embed/_kER_KB_quY" frameborder="0" allowfullscreen></iframe>
<p>Style: The Starry Night</p>
<h5>
<a id="designer-templates" class="anchor" href="#bunny" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Big Buck Bunny (8m 2s)</h5>
<iframe width="560" height="315" src="https://www.youtube.com/embed/IbwxVArl8zk" frameborder="0" allowfullscreen></iframe>
<p>With the help of <a href="https://github.com/nagadomi/waifu2x">Waifu2x</a> super-resolution tool, we are able to make 1080p and 4K HD stylized videos without too much computational cost for stylization.</p>
<h6>
<a id="designer-templates" class="anchor" href="#b1080" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>1080p</h6>
<iframe width="560" height="315" src="https://www.youtube.com/embed/OA3AoLOyLu0" frameborder="0" allowfullscreen></iframe>
<p>Style: The Starry Night</p>
<h6>
<a id="designer-templates" class="anchor" href="#b1080" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>4K</h6>
<iframe width="560" height="315" src="https://www.youtube.com/embed/61nrG1fCfz0" frameborder="0" allowfullscreen></iframe>
<h5>
<a id="designer-templates" class="anchor" href="#doraemon" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Doraemon (22m 39s)</h5>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aAaPKPcTaxs" frameborder="0" allowfullscreen></iframe>
<p>Styles (from left to right): Composition VII, The Great Wave off Kanagawa, The Starry Night</p>

<h3>
<a id="designer-templates" class="anchor" href="#compare" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Compare to Other Methods</h3>

<p>The following videos compare our method with other methods</p>
<h5>
<a id="designer-templates" class="anchor" href="#sample_story_cmp" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Sample Story (15s)</h5>
<iframe width="560" height="315" src="https://www.youtube.com/embed/PTlaByLz6I0" frameborder="0" allowfullscreen></iframe>
<p>Resolution: 640*480</p>
<table>
<thead>
<tr><th>Label (As in Video)</th><th>Method</th><th>Time</th></tr>
</thead>
<tbody>
<tr><td>Ruder et al. (30 iterations)</td><td>Ruder's method, 30 iterations</td><td>0.80 hour</td></tr>
<tr><td>Johnson et al. (Real-time)</td><td>Simply run Johnson's method for each frame</td><td>77.8 seconds</td></tr>
<tr><td>Ruder et al. (1000 iterations)</td><td>Ruder's method, 1000 iterations</td><td>7.56 hours</td></tr>
<tr><td>Our method (30 iterations), no pixel loss</td><td>Our method, with pixel-loss weight 0</td><td>0.80 hour</td></tr>
<tr style="color:#66ccff"><td>Our method (30 iterations), with pixel loss</td><td>Our method, with pixel-loss weight 1.5e-3</td><td>0.80 hour</td></tr>
</tbody>
</table>
<h5>
<a id="designer-templates" class="anchor" href="#bunny_cmp" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Big Buck Bunny (8m 2s)</h5>
<iframe width="560" height="315" src="https://www.youtube.com/embed/EKJs2_iJVYk" frameborder="0" allowfullscreen></iframe>
<p>Resolution: 960*540</p>
<table>
<thead>
<tr><th>Label (As in Video)</th><th>Method</th><th>Time</th></tr>
</thead>
<tbody>
<tr><td>Naive</td><td>Simply run Johnson's method for each frame</td><td> / </td></tr>
<tr><td>Without Pixel Loss</td><td>Our method, with pixel-loss weight 0</td><td>33 hours</td></tr>
<tr style="color:#66ccff"><td>With Pixel Loss</td><td>Our method, with pixel-loss weight 1.5e-3</td><td>33 hours</td></tr>
</tbody>
</table>
<h5>
<a id="designer-templates" class="anchor" href="#doraemon_cmp" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Doraemon (22m 39s)</h5>
<iframe width="560" height="315" src="https://www.youtube.com/embed/mL_dCGtST-0" frameborder="0" allowfullscreen></iframe>
<p>Resolution: 640*480</p>
<table>
<thead>
<tr><th>Label (As in Video)</th><th>Method</th><th>Time</th></tr>
</thead>
<tbody>
<tr style="color:#66ccff"><td>With Temporal Consistency</td><td>Our Method</td><td>58 hours</td></tr>
<tr><td>No Temporal Consistency</td><td>Simply run Johnson's method for each frame</td><td>1.89 hours</td></tr>
<tr><td> / </td><td>Ruder et al. (1000 iterations)</td><td>(predict) ~23 days</td></tr>
</tbody>
</table>
<h5>
<a id="designer-templates" class="anchor" href="#cmp_notes" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Notes</h5>
<p>All time cost above does not contain time cost for calculating optical flow. This procedure can be paralleled with video stylization and calculating 
optical flow itself can be paralleled. In addition, we don't need to calculate optical flow again if we just want to change style for a video. 
We use CPU cluster to calculate optical flow. For Doraemon video, optical flow calculation cost ~50 hours.</p>
   </section>
    </div>

    
  </body>
</html>
